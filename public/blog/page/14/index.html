
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Naildrivin' &#10106;</title>
  <meta name="author" content="David Bryant Copeland">

  
  <meta name="description" content="Currently working on a project where Subversion is the CM system of choice. I&#8217;d like to use git, as it&#8217;s faster and doesn&#8217;t require &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://www.naildrivin5.com/blog/page/14/index.html">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Naildrivin' &#10106;" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-10518541-5']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


  <meta name="google-site-verification" content="h_yTpXa6N3ebHj8DYmgX4lIFGHBW1NtGMVHfXuu7i_4" />
</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Naildrivin' &#10106;</a></h1>
  
    <h2>&#10144; Website of David Bryant Copeland</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:www.naildrivin5.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="http://www.theseniorsoftwareengineer.com">My New Book!</a></li>
  <li><a href="/scalatour">Scala Tour</a></li>
  <li><a href="/talks">Talks</a></li>
  <li><a href="/blog/archives">Blog Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2008/04/28/git-and-svn-connecting-git-branches-to-svn-branches.html">Git and SVN: Connecting Git Branches to Svn Branches</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2008-04-28T00:00:00-04:00" pubdate data-updated="true">Apr 28<span>th</span>, 2008</time>
        
      </p>
    
  </header>


  <div class="entry-content">Currently working on a project where Subversion is the CM system of choice.  I&#8217;d like to use git, as it&#8217;s faster and doesn&#8217;t require so much network access.  Plus, I&#8217;m hoping when it comes time to merge, I can simplify the entire process by using git&#8217;s allegedly superior merging technique.  At any rate, I&#8217;ve got a branch on SVN to work on, and I want to track both that branch and the entire svn tree.

Saturday morning, I did a <tt>git-svn init</tt> from their repository.  Today, after lunch, it finished.  After doing a <tt>git-gc</tt> to clean up the checkout, it wasn&#8217;t clear how to connect branches.  Following is what I did (assume my subversion branch is <tt>branches/FOO</tt>):

<blockquote><pre>
git-checkout -b local-trunk trunk
git branch local-foo FOO
</pre></blockquote>

The first thing creates a new branch called &#8220;local-trunk&#8221; started at &#8220;trunk&#8221; (which is the remote branch mapping to the subversion main trunk).  The second command creates a new branch called &#8220;local-foo&#8221;, which is rooted at remote branch &#8220;FOO&#8221;.  I have no clue why I couldn&#8217;t do the same thing twice, as both commands seem to do the same thing (the first switches to the branch &#8220;local-trunk&#8221; after creating it).  But, this is what worked for me.

Now, to develop, I <tt>git checkout local-foo</tt> and commit all day long.  a <tt>git-svn dcommit</tt> will send my changes to subversion on the FOO branch.  I can update the trunk via <tt>git checkout local-trunk</tt> and <tt>git-svn rebase</tt>.  My hope is that I can merge from the trunk to my branch periodically and then, when my code is merged to the trunk, things will be pretty much done and ready to go.  We&#8217;ll see.

On a side note, the git repository, which contains <b>every revision of every file in the subversion repository</b> is 586,696 bytes.  The subversion checkout of <b>just the FOO branch</b> is 1,242,636 bytes; over double the size, and there&#8217;s still not enough info in that checkout to do a log or diff between versions.
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2008/04/21/rest-security-signing-requests-with-secret-key-but-does-it-work.html">REST Security: Signing Requests With Secret Key, but Does It Work?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2008-04-21T00:00:00-04:00" pubdate data-updated="true">Apr 21<span>st</span>, 2008</time>
        
      </p>
    
  </header>


  <div class="entry-content">Both <a href="http://docs.amazonwebservices.com/AmazonS3/2006-03-01/gsg/?ref=get-started">Amazon Web Services</a> and the <a href="http://www.flickr.com/services/api/auth.howto.web.html">Flickr Services</a> provide <a href="http://en.wikipedia.org/wiki/Representational_State_Transfer">REST</a> APIs to their services.  I&#8217;m currently working on developing such a service, and noticed that both use signatures based on a shared secret to provide security (basically using a <a href="http://en.wikipedia.org/wiki/HMAC">Hash Message Authentication Code</a>).

It works as follows:
<ol>
<li>Applications receive a shared secret known only to them and the service provider.</li>
<li>A request is constructed (either a URL or a query string)</li>
<li>A digest/hash is created using the shared secret, based on the request (for Flickr, the parameter keys and values are assembled in a certain way, so that Flickr can easily generate the same string)</li>
<li>The digest is included in the request</li>
<li>The service provider, using the shared secret, creates a digest/hash on the request it receives</li>
<li>If the service provider&#8217;s signature matches the one included in the request, the request is serviced</li>
</ol>

It&#8217;s actually quite simple, and for one-time requests, is effective.  The problem, however, is that anyone intercepting the request can make it themselves, without some other state being shared with the client and service provider.  Consider a request for an image.  The unsigned request might look like:

<code>http://www.naildrivin5.com/api/images?image_id=45&type=jpg</code>

The signed request, would look like so:

<code>http://www.naildrivin5.com/api/images?image_id=45&type=jpg&signature=34729347298473</code>

So, anyone can then take that URL and request the resource.  They don&#8217;t need to know the shared secret, or the signature algorithm.  This is a bit of a problem.  One of the advantages of REST is that URLs that request resources are static and can be cached (much as WWW resources are).  So, if I wish to protect the given URL, how can I do so?

<h3>HTTP Authentication</h3>

The usual answer is HTTP Authentication; the service provide protects the resource, and the client must first log in.  Login can be done programmatically, and this basically accomplishes sending a second shared secret with the request that cannot be easily intercepted.  HTTP Auth has its issues, however, and might not be feasible in every context.

Another way to address this is to provide an additional piece of data that makes each request unique and usable only once.  To do so requires state to be saved on the client and the server.

<h3>Negotiated One-time Token</h3>

Authentication can be avoided by using the shared secret to establish a token, usable for one request of the given resource.  It would work like this:
<ol>
<li>Client requests a token for a given resource</li>
<li>Service Provider creates a token (via some uuid algorithm ensuring no repeats) and associates it with the resource</li>
<li>Client creates a second request, as above, for the resource, including the token in the request</li>
<li>Service Provider checks not just for a valid signature, but also that the provided token is associated with the given resource</li>
<li>If so, the token is retired, and the resource data is returned</li>
</ol>

Here, the URL constructed in step 3 can be used only once.  Anyone intercepting the request can&#8217;t make it again, without constructing a new one, which they would be unable to do without the shared secret.  Further, this doesn&#8217;t preclude caching.  The main issue here is that since two requests are required, simultaneous access to one resource could result in false errors: if Client A acquires a token, and Client B requests one before Client A <b>uses</b> the token, Client A&#8217;s token could be squashed, resulting in an error when he makes his request.  The service provider can alleviate this by allowing the issuance of multiple active tokens per resource.

<h3>Timestamp</h3>

A disadvantage to the One-Time Token method is that it requires two requests of the service provider for every actual request (one to get the token and one to request the resource).  A way around that is to include a timestamp in the request.  This would work as follows:

<ol>
<li>Client creates request, including the current time.  This request is signed as per above procedure</li>
<li>Service provider validates the request and compares it&#8217;s time with the given timestamp.</li>
<li>If the difference in the service provider&#8217;s time and the client&#8217;s provided time is within some tolerance, the request is serviced</li>
</ol>

This obviously requires the two clocks to be vaguely in sync.  It also allows the resource to be requested by anyone within the timespan of the tolerance.  But, it does save a second request to the client.

<h3>Self-created One-time Token</h3>

This is an amalgam of the Timestamp solution and the Negotiated One-time Token solution.  Here, the client creates its own token, as a simple integer of increasing value.  The server maintains the last requested value and accepts only requests with a higher number:

<ol>
<li>Client creates request, using a global long-lived number</li>
<li>Client signs requests and sends it to the service provider</li>
<li>Service provider validates the signature and compares the provided numeric token with the one last used (the tokens can be globally scoped, or scoped for a given resource)</li>
<li>If the provided numeric token is greater than the previous, the request is serviced</li>
<li>The Client increments his numeric token for next time</li>
</ol>

As with the Timestamp solution, only one request is required.  As with the negotiated one-time token solution, the URL can never be used twice.  The main issue here is if the client forgets its numeric token.  This could be addressed with an additional call to re-establish the token, made only when the Client has determined it no longer knows the last used value.

Unfortunately, this is much more susceptible to race conditions than the Negotiated one-time token.  Since the service provider doesn&#8217;t know what tokens to expect (only that they should be greater than the last requested one), the client has to ensure that the &#8220;create request, submit request, receive response, update local numeric token&#8221; cycle is atomic.  That is not straightforward.

<b>Update</b> Got another idea from a co-worker

<h3>Session Token</h3>

When a user access the system that uses the REST API, they get issued a token (via the REST API).  This token is just like a session token, with an inactivity timeout and so forth.  The token can be manually invalidated via the API, so that when a user logs out or completes some logical task, the token can be invalidated.

This suffers none of the problems of the other solutions, though it isn&#8217;t the most secure.  However, the security problem it has (using the valid URL before the session times out) is fairly minor, and the tradeoff of getting one request per actual request and no race conditions makes it probably the best way to go.
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2008/04/17/shell-history-meme.html">Shell History Meme</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2008-04-17T00:00:00-04:00" pubdate data-updated="true">Apr 17<span>th</span>, 2008</time>
        
      </p>
    
  </header>


  <div class="entry-content">In response to the rage-of-the-moment <a href="http://raibledesigns.com/rd/entry/history_meme">shell history</a> meme, I present my list, which looks different than a lot of peoples&#8217;:
<ul>
<li><b>149</b><tt> cd</tt> - Well, duh</li>
<li><b>104</b><tt> ./run.sh</tt> - Occasionally to run JBoss (I have to have two JBoss servers running locally, and when I do a complete recompile/redeploy (not often), I must restart, as ant fstats the ever-loving shit out thousands of files (multiple times, per, &#8216;natch, cause it so superior to <tt>make</tt>) at the same time JBoss is hot-deploying (twice) and my machine just dies), but more often to run the application I&#8217;m developing.</li>
<li><b>88</b><tt> tail</tt> - To read log files (were I on OS X, Console.app would be the way to go)</li>
<li><b>84</b><tt> ls</tt> - Well, duh</li>
<li><b>73</b><tt> git</tt> - I <code>commit</code> a lot, I <code>diff</code> alot, I <code>stat</code> alot, and I <code>blame</code> alot.  <a href="http://www.naildrivin5.com/daveblog5000/?p=32">You should, too</a></li>
<li><b>57</b><tt> sqlshell.pl</tt> - Awesomely awesome command-line SQL client written by my co-worker and enhanced on occasion by me.  I&#8217;ll probably steal it when I leave this project, and I wish he&#8217;d put it up on sourceforge</li>
<li><b>51</b><tt> jobs</tt> - To find out which JBosses to kill (frequently executed in the wrong shell window)</li>
<li><b>44</b><tt> kill</tt> - To then go kill JBoss</li>
<li><b>43</b><tt> vi</tt> - To get some work done</li>
</ul>

Runners up: <code>rm</code>, <code>grep</code>, <code>git-svn</code>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2008/04/15/distributed-version-control-with-git-for-code-quality-and-team-organization.html">Distributed Version Control With Git for Code Quality and Team Organization</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2008-04-15T00:00:00-04:00" pubdate data-updated="true">Apr 15<span>th</span>, 2008</time>
        
      </p>
    
  </header>


  <div class="entry-content">In <a href="http://www.naildrivin5.com/daveblog5000/?p=31">my previous post</a>, I outlined a code review process I&#8217;ve been using with reasonably effectiveness.  It&#8217;s supported, in my case, by <a href="http://git.or.cz">the Git</a> source code management tool (most known for it&#8217;s use in managing the Linux kernel).  Git or, more generally, distributed development, can encourage some good quality control procedures in teams working on enterprise software.  The lessons learned from the open source world (and the Linux kernel, in particular) can be applied outside the world of OSS and to the consultant-heavy world of enterprise/in-house software development.

The project I&#8217;ve been working on for the past several months has undergone what I believe to be a common change on in-house/enterprise software, which is that several new developers are being added to the project.  Outside of the learning curve required with any new system, many of them are not seasoned Java developers, or are otherwise missing experience in some key technologies in use.   While <a href="http://www.naildrivin5.com/daveblog5000/?p=31">code reviews</a> are a great way to ensure these developers are doing things the right way, there is still concern that their ability to commit to source control could be problematic for the entire team.

Consider a developer breaking the build, or incorrectly refactoring a key piece of shared code.  A review of their commit and some continuous integration can help identify these problems, but, once identified, they must be removed from the codebase.  In the meantime, the development team could be stuck with an unusable build.  This can lead to two bad practices:
<ul>
<li>Commit very rarely</li>
<li>Get new changes from the repository only when absolutely  needed</li>
</ul>
These &#8220;anti-practices&#8221; result in unreadable commit logs, difficult (or skipped) code reviews, duplication of code, and a general discoherence of the system.  This is primarily due to the way most common version control systems work. 

In reserved-checkout systems (e.g. PVCS, StarTeam) <strong>and</strong> concurrent systems (CVS, Subversion), there is the concept of the <b>one true repository of code</b> that is a bottleneck for all code on the project.  The only way Aaron can use Bill&#8217;s code is for Bill to commit it to the repository and for Aaron to check it out (along with anything else committed since the last time he did so).  The only way Carl can effectively review Dan&#8217;s code, or for the automated build to run his test cases, is to checkout code from the repository and examine/run it.  <b>This</b> reality often leads to situations where each developer is operating on his own branch.  The problem here is that CVS and Subversion suck at merging.  This makes the branching solution effectively useless.

Enter Git.  With Git, there is no central repository.  Each developer is on his own branch (or his own copy of someone&#8217;s branch) and can commit to their heart&#8217;s content, whenever <b>they</b> feel they have reached a commit point.  Their changes will <b>never</b> be forced upon the rest of the team.  So, how does the code get integrated?

Developer&#8217;s submit their code to the team lead/integrator (who is the ultimate authority on what code goes to QA/production/the customer), who then reviews it and either accepts or rejects it.  If code is rejected, the team lead works with the developer to get it accepted (either via a simple email of the issues, or more in-depth mentoring as needed).  Git makes this painless and fast, because it handles merging so well.

Consider how effective this is, especially when managing a large (greater than, say, five) team of developers working concurrently.  The only code that gets into the production build will have been vetted through the team lead; he is responsible for physically applying each developer&#8217;s patches (an action that takes a few minutes or even seconds in Git).  Further, developers get instant feedback on their code quality.  In most cases, bad commits are the result of ignorance and lack of experience.  A code review, with instant feedback, is a great way to address both of those issues, resulting in a better developer and a better team, based on open, honest, and immediate communication.

Here&#8217;s how to set this up:
<ol>
<li><b>Assign a team lead to integrate the code</b> - this is a senior <i>developers</i> who can assess code quality, provide mentoring and guidance and can be trusted to put code into the repository destined for QA and production</li>
<li><b>Each developer clones the team lead&#8217;s repository</b> - This is done to baseline the start of their work</li>
<li><b>Developers commit, branch, merge, and pull as necessary</b> - Since Git makes merging simple, developer&#8217;s can have full use of all features of version control and can do so in their environment without the possibility of polluting the main line of development.  They can also share code amongst themselves, as well as get updates from the team lead&#8217;s repository of &#8220;blessed&#8221; code<sup><a href="#1">1</a></sup></li>
<li><b>Developer&#8217;s inform the lead of completion</b></li>
<li><b>Lead pulls from their repository</b> - The lead reviews the developer&#8217;s changes and applies the patch to his repository.  He can then exercise whatever quality control mechanisms he wishes, including automated tests, manual tests, reviews, etc<sup><a href="#2">2</a></sup>.
<li><b>Lead rejects patches he doesn&#8217;t agree with</b> - If the patch is wrong, buggy, or just not appropriate in some way, the lead rejects the patch and provides the developer with information on the correct approach</li>
<li><B>Lead accepts patches he does agree with</b> - If the lead agrees with the patch, he applies it to his repository, where it is now cleared for QA</li>
</ol>

This may seem convoluted, but it actually carries little overhead compared to a junior developer performing a &#8220;nuclear bomb&#8221; commit that must then be rolled back.  For much larger teams, the approach can be layered, with the primary team lead accepting patches only from lieutenants, who accept patches from the primary developers.

Unlike a lot of hand-wavy processes and practices, this model has been demonstrated effective on virtually <b>every open source project</b>.  Even though the Linux kernel is one of the few to use technology to support this process (Git), every other large OSS project has the concept of &#8220;committers&#8221; who are the people allowed to actually commit.  Anyone else wishing to contribute must submit patches to a committer, who then reviews and approves of their patch (or not).

I belive this would be highly effective in a professional environment developing in-house or enterprise software (especially given the typical love of process in those environments; <b>this</b> process might actually help!).  I have been on at least three such projects where it would&#8217;ve been an enormous boon to quality (not to mention that the natural mentoring and feedback built into the process would&#8217;ve been hugely helpful for the more junior developers).

<hr />
<a name="1"><b>1</b></a> <i>Git even allows a developer to merge certain <b>commits</b> from one branch to another.  Suppose Frank is working on a large feature, and happens to notice a bug in common code.  He can address that bug and commit it.  Gary can then merge only that commit into his codebase to get the bugfix, without having to also take all of Frank&#8217;s in-progress work on the large feature.  Good luck doing that with StarTeam.</i><br />
<a name="2"><b>2</b></a> <i> A CI system could be set up in a variety of ways:  it could run only against the lead&#8217;s &#8220;blessed&#8221; repository, or it could run against an intermediate repository created by the lead (who then blesses patches that pass), or it could be totally on its own and allow developers to submit against it prior to submitting to the lead.
</i>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2008/04/03/quick-and-dirty-code-reviews-check-commit-logs.html">Quick and Dirty Code Reviews: Check Commit Logs</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2008-04-03T00:00:00-04:00" pubdate data-updated="true">Apr 3<span>rd</span>, 2008</time>
        
      </p>
    
  </header>


  <div class="entry-content"><blockquote><pre>             Large maintenance 
+          aggressive schedule 
+       lots of new developers 
+ minimal system documentation
______________________________
 Need for highly efficient and 
       effective QA procedures</pre></blockquote>

Where I&#8217;ve been working for the past few months, we&#8217;ve been under the gun to meet an aggressive deadline.  As management is want to do, they&#8217;ve added several new developers to the project.  One of the many reasons why adding developers is ultimately a bad thing is that, in addition to the complexity in communication, there is a risk of innocent well-developed code being added to the codebase that is Just Plain Wrong.  Our system has been in development for many years and contains a wide variety of coding styles, implementation patterns and idioms.  Some of them should Never Be Followed Again, and some are the Correct Way of Doing Things.   There&#8217;s really no easy way for a new developer to know what is what.

Now, outside of going back in time, creating pedantic test cases, gathering requirements and incessantly refactoring, we need an option to make sure bad code doesn&#8217;t get into the codebase.  By &#8220;bad&#8221; I don&#8217;t mean poorly written or buggy code, I mean code that does not fit into the system as a whole.  For example, a developer was writing some code to generate printable reports.  His implementation resulted in a very nice report popping up in a Swing window in our application (our application is a Swing front-end to a JEE back-end).  It was very well-implemented and looked great.  However, everywhere else in the application, reports are generated by writing a PDF to disk and asking Windows (via JDIC) to &#8220;view&#8221; the file.  This is the code I&#8217;m talking about.

<h3>Finding bad code</h3>
At the start of the project, we went through the arduous process of identifying each bit of work in an MS-Project file and assigning developers to it.  New developers were given tasks that didn&#8217;t touch core components, while experienced developers got tasks involving major refacotrings or database changes.  Our project lead suggested that each module undergo a code review.  It sounds reasonable, however all of us let out a collective groan at the thought of wrangling together 3-4 developers once a week for an hour or two to go over printouts or screenfulls of code, much of which was simply being modified.

One of the senior developers proposed the solution we ultimately went with: senior developers get emailed the diffs of all commits and make sure to spend some time reading and reviewing those commits.  Coupled with our policy of &#8220;commit early, commit often&#8221;, this has worked out great.

<h3>Diff-based code review</h3>

Here&#8217;s what you need:

<ul>
<li>A concurrent version control system developers trust.  Recommed <a href="http://git.or.cs">Git</a> or <a href="http://subversion.tigris.org">Subversion</a> if you must.</li>
<li>A simple script to email diffs on <b>every</b> commit.  Usually included as an example hook for must version control systems.</li>
<li>IM clients (Google talk within GMail works in even the most oppressive environment)</li>
<li>A sane version control policy: committed code must:
    <ul>
    <li>Compile</li>
    <li>Not prevent application deployment/startup</li>
    <li>Not horribly break someone else&#8217;s code (optional)</li>
    </ul>
    Developers should commit as frequently as they want (and preferably frequently).  I typically commit code I feel is &#8220;done&#8221; but that might not add up to an actual feature.  This requires accepting that <b>head is not a real verison</b>.  Most real version control systems have the ability to tag, branch, etc.  These features are for &#8220;real working versions&#8221;.  The head of the trunk is not.</li>
<li>A sane coding style policy: if you must re-indent or change bracing style, do it in its own commit, outside of actual code changes.  Better yet, don&#8217;t do it at all.  Formatting changes can obscure the history of a piece of code and should be made minimally, if at all. </li>
</ul>

The &#8220;process&#8221; (if you want to even call it that) is:

<ol>
<li>Diffs get emailed to the senior developers as soon as they happen</li>
<li>Senior Developers read the diffs, using IM to discuss any issues</li>
<li>If code does have issues, the diff is forwarded to the developer who committed, with comments on what to change and why (senior developers decide amongst themselves who will send the feedback, or a &#8220;lead developer&#8221; can, if one is identified)</li>
</ol>

Part of this requires some level of diplomacy, however a plain, to-the-point email on what the issues are with a piece of code, why the changes should be made, and a suggestion on how to make them should be digestible by anyone.

I&#8217;ve had great success with this, having caught a wide variety of problems (even in my code, by others) without having to have <b>one</b> meeting or to print out <b>one</b> sheet of code.  The fact is, on a maintenance project, you aren&#8217;t reviewing the codebase, but <b>changes</b> to that codebase.  Diffs are the way to understand what changes are being made.
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/12/01/imports-considered-annoying-and-pointless.html">Imports Considered Annoying and Pointless</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2007-12-01T00:00:00-05:00" pubdate data-updated="true">Dec 1<span>st</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content">What is really the point of import statements in Java?  Am I meant to believe that while perl, vim, find, eclipse, emacs, or any other tool written in the last decade can locate my class files that <tt>javac</tt> cannot?  Couldn&#8217;t javac, when faced with a usage of the class <tt>ArrayList</tt>, figure out that since the <b>only fucking class named <tt>ArrayList</tt></b> available to it is in <tt>java.util</tt> that <b>that might possibly</b> be the class I mean?  

Other than resolving ambiguities, imports are a manual way to accomplish what the compiler could much more easily.  Plus, removing them would reduce pointless coupling, improve maintenance and result in a class header that provided actual value, and not a shitload of lines to fold and skip over.

<ul>
<li><b>But imports help the compiler locate classes!</b> - Why should I help the compiler locate classes?  Why put a fully automatable task in the hands of a developer?  Are you telling me the compiler can&#8217;t index the classpath to more efficiently search at compile-time?</li>
<li><b>But imports let you know class dependencies</b> - No, they don&#8217;t.  Only if you don&#8217;t use star imports and only if you import <strong>only</strong> what you need would this be the case.  However, not really, because your class could <tt>Class.forName</tt>.  And, honestly, how much time do you spend looking at the import statements to perform this analysis?  An automated tool could provide this information much more correctly and completely</li>
<li><b>But how would I know what classes are in a jar and what are in the codebase?</b> - You&#8217;d know the same way the compiler knows.  And, to be honest, the code should be written for the maintainers, not for the new kids.  Anyone new to a codebase can, relatively quickly, figure out what is in the code base and what isn&#8217;t.  This, along with proper tools for locating classes integrated into your IDE would be much better than looking at import statements and grep&#8217;ing the output of <tt>jar tvf</tt>.
</ul>

I think an approach the addresses the above concerns without adding a lot of cruft is to redefine what we mean by &#8220;package&#8221;.  In Java parlance, &#8220;package&#8221; is really just a directory used to organize classes and ensure unique naming.  Conceptually, however, a &#8220;package&#8221; is a singular unit.  For example, Apache&#8217;s <tt>commons-lang</tt> contains nine Java packages, but it&#8217;s really only, conceptually, <em>one</em> package.

I think some changes to the language to help us all out would improve things.  Wouldn&#8217;t this be much more readable source code:

<div>
  <pre>
    <code class='java'>package myapp;
// no point in putting the dir-structure as dots, the compiler
// can figure it out.  Instead we indicate that this class, whever
// it is, is part of the conceptual package &quot;myapp&quot;

import commons-lang[2.1,];     // check for version 2.1 or greater
import commons-logging[1.0.*]; // check for version 1.0.* only
import j2ee[5.0,5.3];          // check for any version from 5.0 to 5.3

clarify java.util.Date;

public class Whatever
{
    public static void main(String args[]) 
    {
        Date date = new Date();
        // whatever else
    }
}</code>
  </pre>
</div>


This syntax that I just made up is explicit and much more powerful than import statements.  You declare your version requirements and dependencies in a different way than clearing up ambiguities.  The compiler could even issue warnings when you import things you don&#8217;t use.  It would not be terribly difficult for the compiler to provide this service, and it would keep it in the language and not in the hands of some unwieldy external tool or IDE.

I don&#8217;t know, this just seems fairly obvious to me, and I&#8217;m surprised that Java continues the &#8220;not much better than <tt>#include</tt>&#8221; method of linking things together.
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/11/26/why-is-j2ee-deployment-such-a-nightmare.html">Why Is J2EE/JBoss Configuration Such a Nightmare?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2007-11-26T00:00:00-05:00" pubdate data-updated="true">Nov 26<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content">I&#8217;m glad EJB3 has come along, because it has vastly simplified what you must do to get a J2EE application up and running.  It&#8217;s not 100% smooth, but it&#8217;s a step in the right direction.

That being said, anything beyond simple EJBs and Persistence objects is just such a clusterfuck of configuration, dependencies, undocumented magic strings, masked error messages and XML abuse.   Why was XML chosen as a configuration format for what is basically a properties file.  What is the advantage of this:


<code>
<nobr>&lt;mbean name="big.fucking.long.whatever"&gt;
&lt;attribute name="SomeProperty"&gt;some value&lt;/attribute&gt;
&lt;attribute name="SomeOtherProperty"&gt;another value&lt;/attribute&gt;
&lt;attribute name="TimeWastedTypingAngleBrackets"&gt;10 hours&lt;/attributes&gt;
&lt;attribute name="MoneyWastedPayingForXMLSpy"&gt;$10000&lt;/attribute&gt;
&lt;/mbean&gt;
</nobr></code>

over this:

<code>
big.fucking.long.whatever

SomeProperty=some value
SomeOtherProperty=another value
TimeWastedTypingAngleBrackets=0 seconds
MoneyWastedPayingForXMLSpy=$0
</code>

It seems to me that if all we are doing is configuring a set of properties and values, a format similar to the windows <tt>.ini</tt> format would be much prefered.  And, honestly, if we can&#8217;t do better than Windows, what the fuck.  I guess one thing all three formats have in common is that you have no fucking idea what the attributes mean, which are required or what will happen at runtime.  

If you are lucky, you have the mbean source or javadoc (don&#8217;t forget to look for <tt>is</tt> to precede boolean properties and <tt>get</tt> to precede all others!)  Also, fucking this up generated an Oracle-quality error message from JBoss: &#8220;Attribute SomeProperty not found&#8221;.  So, are you <i>looking</i> for SomeProperty and didn&#8217;t find it, or did you <i>get</i> it and not want it?

Of course, we could, actually, leverage the power of XML and tools like <a href="http://dtddoc.sourceforge.net/">DTDDoc</a> and <a href="http://xframe.sourceforge.net/xsddoc/index.html">XSD Doc</a> and do something like this:

<code><nobr>
&lt;mbean name="big.fucking.long.whatever"&gt;
&lt;SomeProperty&gt;some value&lt;/SomeProperty&gt;
&lt;SomeOtherProperty&gt;another value&lt;/SomeOtherProperty&gt;
&lt;TimeWastedTypingAngleBrackets&gt;10 hours&lt;/TimeWastedTypingAngleBrackets&gt;
&lt;MoneyWastedPayingForXMLSpy&gt;$10000&lt;/MoneyWastedPayingForXMLSpy&gt;
&lt;/mbean&gt;
</nobr></code>

This, if backed by a schema, would actually be a nice way to document (and enforce) configuration.

Bonus points to Hibernate for allow properties <b>or</b> XML <b>or</b> MBean configuration and for having the property names <b>different in each fucking format</b>.  It seems like a lot of extra work to make them all different.

I&#8217;m not saying I want a Microsoft Enterprise Application Wizard, but a little common sense could go a long way.

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2006/06/29/google-maps-pedometer.html">Google Maps Pedometer</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2006-06-29T00:00:00-04:00" pubdate data-updated="true">Jun 29<span>th</span>, 2006</time>
        
      </p>
    
  </header>


  <div class="entry-content">I love <a href="http://www.gmap-pedometer.com">this thing, it&#8217;s a </a><a href="http://maps.google.com">Google Maps</a> hack that allows you to plot a course, with waypoints, and show you the distance as well as mile markers.  I&#8217;ve been using it to plot different paths for running specific distances.  You can even save the path for later viewing.  <a href="http://www.gmap-pedometer.com/?r=263601">Here&#8217;s</a> a course I ran the other day for a three mile run.
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2006/06/28/the-power-of-digital-audio.html">The Power of Digital Audio</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2006-06-28T00:00:00-04:00" pubdate data-updated="true">Jun 28<span>th</span>, 2006</time>
        
      </p>
    
  </header>


  <div class="entry-content">So, <a href="http://www.supercadedc.com">my  band</a> has been recording an E.P. and we did all the tracking ourselves.  Before taking things into a studio for mixing, I went through and did all the editing.  I guess in the old days of actual tape, things would be done differently while tracking, because editing tape involves razors, scotch tape and rulers.  With something like Pro Tools, a lot of things can just be handled after the fact.  I dunno, maybe that makes us crappy musicians, but in my mind, it&#8217;s just something that enables us to get our musical ideas recorded with a minima of hassle.

I had figured that editing the vocals together would be the  biggest task.   Basically taking the best phrase from multiple vocal takes and creating a final &#8220;comped&#8221; take for the vocals.  It turns out that a much trickier part involved the drums.  We didn&#8217;t use a click track or metronome, as Michelle keeps reasonably steady time and we just didn&#8217;t have time to rehearse to the click.  The tricky part about this is that anywhere in a song where she&#8217;s not playing, she has to click her sticks so we have a time reference.  See, Tony, Devon and I would be recording our tracks later when she wasn&#8217;t there, so we need a beat at all times during the song.

We&#8217;ve got a couple songs with some multiple-measure stops in them, where Michelle hits a big cymbal crash, the band plays and then she comes back in.  The first thing I noticed was that her stick clicks are in the middle of the decay of the cymal crash, like so:

<img src="images/protools/Original.jpg"/>

Now, I could just fade out right before the first click, but that would be highly awkward sounding.  I could simply remove the click, but then there would be a noticable gap in the cymbal decay.  So, Time Expansion to the rescue!  First step, cut out the portion with the click sound:

<img src="images/protools/SectionToFix.jpg"/>

Next step, select an area of the cymbal decay adjacent and previous to the area I just removed, and use the time expansion/compression plug in to stretch it to fill the remaining space, without modifying the pitch:

<img src="images/protools/Plugin.jpg"/>

Note that I had to calculate the amount of space to fill via samples, and ensure that the &#8220;Sound vs. Rhythm&#8221; slider was all the way on Sound, or you get a noticable flanging effect.  Once that&#8217;s done, we get this:

<img src="images/protools/AfterExpansion.jpg"/>

which works OK, but there&#8217;s noticeable clicks when we pass from the edited audio to the unedited audio.  A quick crossfade of both sections gives us

<img src="images/protools/Faded.jpg"/>

and then we do it about 11 more times.  The result

<img src="images/protools/Fixed.jpg"/>

is a smooth cymbal decay without any sound of stick clicks!

I guess if we&#8217;d been doing this with tape, we would either have had to use a click track or have someone else click the missing rhythm in Michelle&#8217;s headphones.  Either way, I didn&#8217;t even think about this problem at the time and thank God I was able to fix it.  Go Pro Tools!
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2006/06/20/wikipedia-and-the-speed-of-ebusiness.html">Wikipedia and the Speed of eBusiness</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2006-06-20T00:00:00-04:00" pubdate data-updated="true">Jun 20<span>th</span>, 2006</time>
        
      </p>
    
  </header>


  <div class="entry-content">So, I&#8217;ve authored a few <a href="http://en.wikipedia.org">Wikipedia</a> entries, and have done large edits to some other, so usually a few times a week, I&#8217;ll check the watchlist and keep an eye on things.  I&#8217;ll also periodically fix typos or reword things in articles if I&#8217;m reading.  Usually I&#8217;ll only bother for articles about old school video games, wrestling or music.  I was reading the entry on amateur wrestler-turned-sports-entertainer <a href="http://en.wikipedia.org/wiki/Brock_Lesnar">Brock Lesna</a> and notice some pretty poorly worded passages.  A big problem with pro-wrestling entires is that they don&#8217;t clearly distinguish wrestling storylines from real-world happenings and they come off a bit <a href="http://en.wikipedia.org/wiki/Mark_%28professional_wrestling%29">markish</a>.  

So, I edited a big part of the entry about his time in WWE.  I try to preview before saving, but whenever I edit a lot of text, I end up making several follow-up edits.  After a couple of these, I notice a missing comma, so I click &#8220;Edit&#8221; and I get a blank page.  Figuring wikipedia just barfed or something, I try it again.  Nothing.  I had been just editing the section, so I go back and try to edit the entire article.  It has been replace with <a href="http://en.wikipedia.org/w/index.php?title=Brock_Lesnar&oldid=59628589">this (possibly NSFW) entry</a>.  Right under my nose!  So, I reverted the edit and went to the user&#8217;s talk page.  I then had to get searching through the Wikipedia help section to find out how to flag this guy as a vandal.  Meanwhile, he reverted my reversion to his vandalized page <b>again</b>!  Another wikipedia user (possibly someone who was watching his talk page) undid his edits.  

I finally figured out a) how to put a vandal tag on his talk page (he&#8217;s got a ton there already) and then b) how to inform the Wikipedia admins that he was a repeat offender and needed banning.  Within a few minutes of that, I got a message that he was banned for one week and that this was the third time he&#8217;d been banned.  The entire thing from start to finish was about 5 minutes. Kudos to the openness of wikipedia!  Now the world can be more accurately informed about how Brock Lesnar almost broke his neck at Wrestlemania only to get buried by Stone Cold Steve Austin on his way out the door!
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/15/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/13/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>About Me</h1>
  <p>
  <img class="left" src="http://www.gravatar.com/avatar/ae52d95bbc43d0a62044a9a6b5674de0.png">
  I&#8217;m a programmer, musician, and <a href="http://www.theseniorsoftwareengineer.com">author</a>.  I speak frequently at national and regional conferences and spend my days currently as a lead engineer at <a href="http://www.stitchfix.com">Stitch Fix</a>. I&#8217;ve written applications in C, C++, Perl, Ruby, Scala, and many others, on large and small teams. As a developer, I believe in clean code, making it right, providing a great user experience and using the right tool for the job.  As a bass player, I believe in using a pick, locking it down, and ripping off Peter Hook.  As an author, I insist on the Oxford Comma, try to avoid semi-colons, and dislike title case.
  </p>
</section>
<section>
  <p>
  <a href="http://www.theseniorsoftwareengineer.com"><img class="center" src="http://www.theseniorsoftwareengineer.com/images/cover.png"></a>
  <a href="http://pragprog.com/book/dccar/build-awesome-command-line-applications-in-ruby"><img class="center" src="http://imagery.pragprog.com/products/249/dccar_xlargebeta.jpg?1319573406"></a>
  </p>
</section>

<section>
  <h1>Github Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/davetron5000">@davetron5000</a> on Github
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'davetron5000',
            count: 5,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>


<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("davetron5000", 5, true);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/davetron5000" class="twitter-follow-button" data-show-count="false">Follow @davetron5000</a>
  
</section>

<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2013/12/02/introduction-to-gli.html">&#10106;&#10144; Introduction to GLI</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/11/18/square-wallet-is-almost-awesome.html">&#10106;&#10144; Square Wallet is Almost Awesome</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/10/14/self-vs-professional-publishing.html">&#10106;&#10144; Self vs Professional Publishing</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/09/27/an-introvert-goes-to-dinner.html">&dagger; An Introvert Goes to Dinner</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/09/13/my-book-is-on-sale.html">&dagger; My Book is On Sale</a>
      </li>
    
  </ul>
</section>

  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - David Bryant Copeland -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
